{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance optimization overview\n",
    "\n",
    "This tutorial illustrates the performance optimizations applied to the code generated by an `Operator`. As we shall see, most optimizations are automatically applied as they're known to systematically improve performance. Others, whose impact varies across different `Operator`s, are instead to be enabled through specific options.\n",
    "\n",
    "An Operator has several preset **optimization levels**; the fundamental ones are `noop` and `advanced`. With `noop`, no performance optimizations are introduced by the compiler. With `advanced`, several flop-reducing and data locality _optimization passes_ are performed. Examples of flop-reducing optimization passes are common sub-expressions elimination and factorization; examples of data locality optimization passes are loop fusion and cache blocking. SIMD vectorization, via compiler auto-vectorization, is enforced through OpenMP pragmas.\n",
    "\n",
    "An optimization pass may provide knobs, or **options**, for fine-grained tuning. As explained in the next sections, some of these options are given at compile-time, others at run-time.\n",
    "\n",
    "**\\*\\* Remark \\*\\***\n",
    "\n",
    "Parallelism -- both shared-memory (e.g., OpenMP) and distributed-memory (MPI) -- is _by default disabled_ and is _not_ controlled via the optimization level. In this tutorial we will also show how to enable OpenMP parallelism (you'll see it's trivial!). A mini-guide about parallelism in Devito and related aspects is also available [here](https://github.com/devitocodes/devito/tree/master/benchmarks/user#a-step-back-configuring-your-machine-for-reliable-benchmarking). \n",
    "\n",
    "**\\*\\*\\*\\***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "The optimization level may be changed in various ways:\n",
    "\n",
    "* globally, through the `DEVITO_OPT` environment variable. For example, to disable all optimizations on all `Operator`s, one should run with\n",
    "\n",
    "```\n",
    "DEVITO_OPT=noop python ...\n",
    "```\n",
    "\n",
    "* programmatically, adding the following lines to a program\n",
    "\n",
    "```\n",
    "from devito import configuration\n",
    "configuration['opt'] = 'noop'\n",
    "```\n",
    "\n",
    "* locally, as an `Operator` argument\n",
    "\n",
    "```\n",
    "Operator(..., opt='noop')\n",
    "```\n",
    "\n",
    "Local takes precedence over programmatic, and programmatic takes precedence over global.\n",
    "\n",
    "The optimization options, instead, may only be changed locally. The syntax to specify an option is\n",
    "\n",
    "```\n",
    "Operator(..., opt=('advanced', {<optimization options>})\n",
    "```\n",
    "\n",
    "A concrete example (you can ignore the meaning for now) is\n",
    "\n",
    "```\n",
    "Operator(..., opt=('advanced', {'blocklevels': 2})\n",
    "```\n",
    "\n",
    "That is, options are to be specified _together with_ the optimization level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default values\n",
    "\n",
    "By default, all `Operator`s are run with the optimization level set to `advanced` and with all options disabled. So this\n",
    "\n",
    "```\n",
    "Operator(Eq(...))\n",
    "```\n",
    "\n",
    "is equivalent to\n",
    "\n",
    "```\n",
    "Operator(Eq(...), opt='advanced')\n",
    "```\n",
    "\n",
    "and obviously also to\n",
    "\n",
    "```\n",
    "Operator(Eq(...), opt=('advanced', {}))\n",
    "```\n",
    "\n",
    "In virtually all scenarios, regardless of application and underlying architecture, this ensures very good performance -- but not necessarily the very best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "The following functions will be used throughout the notebook for various purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: George -- I guess we could (and should!) move this under examples/performance/utils.py ... \n",
    "def _unidiff_output(expected, actual):\n",
    "    \"\"\"\n",
    "    Helper function. Returns a string containing the unified diff of two multiline strings.\n",
    "    \"\"\"\n",
    "    import difflib\n",
    "    expected=expected.splitlines(1)\n",
    "    actual=actual.splitlines(1)\n",
    "\n",
    "    diff=difflib.unified_diff(expected, actual)\n",
    "\n",
    "    return ''.join(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running example\n",
    "\n",
    "Throughout the notebook we will generate `Operator`s for the following time-marching `Eq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import sin\n",
    "from devito import Eq, Grid, Operator, Function, TimeFunction\n",
    "\n",
    "grid = Grid(shape=(80, 80, 80))\n",
    "\n",
    "f = Function(name='f', grid=grid)\n",
    "u = TimeFunction(name='u', grid=grid, space_order=2)\n",
    "\n",
    "eq = Eq(u.forward, sin(f)*u.dy.dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite its simplicity, this `Eq` is all we need to showcase the key components of the Devito optimization engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenMP Parallelism\n",
    "\n",
    "There are several ways to enable OpenMP parallelism. The one we use here consists of supplying an **option** to an `Operator`. The next cell illustrates the difference between two `Operator`s generated with the `noop` optimization level, but with OpenMP enabled on the latter `Operator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we only need this cell for Continuous Integration, which runs with OpenMP enabled\n",
    "from devito import configuration\n",
    "configuration['language'] = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define _POSIX_C_SOURCE 200809L\n",
      "#include \"stdlib.h\"\n",
      "#include \"math.h\"\n",
      "#include \"sys/time.h\"\n",
      "#include \"omp.h\"\n",
      "\n",
      "struct dataobj\n",
      "{\n",
      "  void *restrict data;\n",
      "  int * size;\n",
      "  int * npsize;\n",
      "  int * dsize;\n",
      "  int * hsize;\n",
      "  int * hofs;\n",
      "  int * oofs;\n",
      "} ;\n",
      "\n",
      "struct profiler\n",
      "{\n",
      "  double section0;\n",
      "} ;\n",
      "\n",
      "\n",
      "int Kernel(struct dataobj *restrict f_vec, const float h_y, struct dataobj *restrict u_vec, const int time_M, const int time_m, struct profiler * timers, const int x_M, const int x_m, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      "{\n",
      "  float (*restrict f)[f_vec->size[1]][f_vec->size[2]] __attribute__ ((aligned (64))) = (float (*)[f_vec->size[1]][f_vec->size[2]]) f_vec->data;\n",
      "  float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "\n",
      "  for (int time = time_m, t0 = (time)%(2), t1 = (time + 1)%(2); time <= time_M; time += 1, t0 = (time)%(2), t1 = (time + 1)%(2))\n",
      "  {\n",
      "    struct timeval start_section0, end_section0;\n",
      "    gettimeofday(&start_section0, NULL);\n",
      "    /* Begin section0 */\n",
      "    #pragma omp parallel num_threads(nthreads)\n",
      "    {\n",
      "      #pragma omp for collapse(1) schedule(dynamic,1)\n",
      "      for (int x = x_m; x <= x_M; x += 1)\n",
      "      {\n",
      "        for (int y = y_m; y <= y_M; y += 1)\n",
      "        {\n",
      "          for (int z = z_m; z <= z_M; z += 1)\n",
      "          {\n",
      "            u[t1][x + 2][y + 2][z + 2] = (-(-u[t0][x + 2][y + 2][z + 2]/h_y + u[t0][x + 2][y + 3][z + 2]/h_y)/h_y + (-u[t0][x + 2][y + 3][z + 2]/h_y + u[t0][x + 2][y + 4][z + 2]/h_y)/h_y)*sin(f[x + 1][y + 1][z + 1]);\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    /* End section0 */\n",
      "    gettimeofday(&end_section0, NULL);\n",
      "    timers->section0 += (double)(end_section0.tv_sec-start_section0.tv_sec)+(double)(end_section0.tv_usec-start_section0.tv_usec)/1000000;\n",
      "  }\n",
      "  return 0;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "op0 = Operator(eq, opt=('noop'))\n",
    "op0_omp = Operator(eq, opt=('noop', {'openmp': True}))\n",
    "\n",
    "# print(op0)\n",
    "# print(_unidiff_output(str(op0), str(op0_omp)))  # Uncomment to print out the diff only\n",
    "print(op0_omp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenMP-ized `op0_omp` `Operator`:\n",
    "\n",
    " - includes the necessary header file `#include \"omp.h\"`\n",
    " - the `#pragma omp parallel num_threads(nthreads)` directive\n",
    " - the `#pragma omp for collapse(...) schedule(dynamic,1)` directive\n",
    " \n",
    "More complex `Operator`s will have more directives, more types of directives, different iteration scheduling strategies based on heuristics and empirical tuning (e.g., `static` instead of `dynamic`), etc.\n",
    "\n",
    "We note how the OpenMP optimization pass also introduces a new symbol, `nthreads`. This allows users to explicitly control the number of threads with which an `Operator` is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op0_omp.apply(time_M=0)  # Picks up `nthreads` from the standard environment variable OMP_NUM_THREADS\n",
    "op0_omp.apply(time_M=0, nthreads=2)  # Runs with 2 threads per parallel loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `advanced` mode\n",
    "\n",
    "As already explained, `advanced` is the default optimization level in Devito. This mode performs several compilation passes to optimize the `Operator` for computation (number of flops), working set size, and data locality.\n",
    "\n",
    "In the next paragraphs we dissect the `advanced` mode and analyze, one by one, some of its key passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop blocking\n",
    "\n",
    "The next cell creates a new `Operator` that adds loop blocking to what we had in `op0_omp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1_omp = Operator(eq, opt=('blocking', {'openmp': True}))\n",
    "print(op1_omp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\*\\* Remark \\*\\***\n",
    "\n",
    "`'blocking'` is **not** an optimization level -- it rather identifies a very specific compilation pass. In other words, the `advanced` mode represents a set of passes, and `blocking` is one such pass.\n",
    "\n",
    "**\\*\\*\\*\\***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `blocking` pass creates additional loops over blocks. In this simple `Operator` there is just one loop nest, so only a pair of additional loops are created. In more complex `Operator`s, several loop nests may individually be blocked, whereas others may be left unblocked -- this is decided by the Devito compiler according to certain heuristics. The size of a block is represented by the symbols `x0_blk0_size` and `y0_blk0_size`, which are runtime parameters akin to `nthreads`. \n",
    "\n",
    "By default, Devito applies 2D blocking and sets the default block shape to 8x8. There are two ways to set a different block shape:\n",
    "\n",
    "* passing an explicit value. In the example below we would run with a 24x8 block shape\n",
    "\n",
    "```\n",
    "op1_omp.apply(..., x0_blk0_size=24)\n",
    "```\n",
    "\n",
    "* letting the autotuner run for a while, looking for a better block shape. There are several autotuning modes. A short summary is available [here](https://github.com/devitocodes/devito/wiki/FAQ#devito_autotuning)\n",
    "\n",
    "```\n",
    "op1_omp.apply(..., autotune='aggressive')\n",
    "```\n",
    "\n",
    "Loop blocking also provides two optimization options:\n",
    "\n",
    "* `blockinner={False, True}` -- to enable 3D (or any nD, n>2) blocking\n",
    "* `blocklevels={int}` -- to enable hierarchical blocking, to exploit the cache hierarchy \n",
    "\n",
    "In the example below, we construct an `Operator` featuring six-dimensional loop blocking, where the first three loops represent outer blocks, whereas the second three loops represent inner blocks within an outer block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1_omp_6D = Operator(eq, opt=('blocking', {'blockinner': True, 'blocklevels': 2, 'openmp': True}))\n",
    "print(op1_omp_6D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMD vectorization\n",
    "\n",
    "Devito enforces SIMD vectorization through OpenMP pragmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2_omp = Operator(eq, opt=('blocking', 'simd', {'openmp': True}))\n",
    "# print(op2_omp)  # Uncomment to see the generated code\n",
    "# print(_unidiff_output(str(op1_omp), str(op2_omp)))  # Uncomment to print out the diff only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code motion\n",
    "\n",
    "The `advanced` mode performs a code motion pass. In explicit PDE solvers, this is most commonly used to lift expensive time-invariant sub-expressions out of the inner loops. The pass is however quite general in that it is not restricted to the concept of time-invariance -- any sub-expression invariant with respect to a subset of `Dimension`s is a code motion candidate. In the example below, we see that `sin(f)` gets hoisted out of the inner loops since it is determined to be an expensive invariant sub-expression. In other words, the compiler trades the redundant computation of `sin(f)` for additional storage (the `r1[...]` array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op3_omp = Operator(eq, opt=('lift', {'openmp': True}))\n",
    "print(op3_omp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic flop-reducing transformations\n",
    "\n",
    "Among the simpler flop-reducing transformations applied by the `advanved` mode we find:\n",
    "\n",
    "* \"classic\" common sub-expressions elimination (CSE),\n",
    "* factorization,\n",
    "* optimization of powers\n",
    "\n",
    "The cell below shows how the computation of `u` changes by incrementally applying these three passes. First of all, we observe how the symbolic spacing `h_y` gets assigned to a temporary, `r0`, due to appearing in several sub-expressions. This is the effect of CSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op4_omp = Operator(eq, opt=('cse', {'openmp': True}))\n",
    "print(_unidiff_output(str(op0_omp), str(op4_omp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factorization causes the collection of `r0` in two different sub-expressions. In larger, more complex examples, the impact of factorization is typically much more pronounced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op5_omp = Operator(eq, opt=('cse', 'factorize', {'openmp': True}))\n",
    "print(_unidiff_output(str(op5_omp), str(op4_omp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no powers in this example, so the `opt-pows` pass has no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op6_omp = Operator(eq, opt=('cse', 'factorize', 'opt-pows', {'openmp': True}))\n",
    "print(_unidiff_output(str(op6_omp), str(op5_omp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-iteration redundancy elimination (CIRE)\n",
    "\n",
    "This is perhaps the most advanced among the optimization passes in Devito. CIRE [1] searches for redundancies across consecutive loop iterations. These are often induced by a mixture of nested, high-order, partial derivatives. The underlying idea is very simple. Consider:\n",
    "\n",
    "```\n",
    "r0 = a[i-1] + a[i] + a[i+1]\n",
    "```\n",
    "\n",
    "at `i=1`, we have\n",
    "\n",
    "```\n",
    "r0 = a[0] + a[1] + a[2]\n",
    "```\n",
    "\n",
    "at `i=2`, we have\n",
    "\n",
    "```\n",
    "r0 = a[1] + a[2] + a[3]\n",
    "```\n",
    "\n",
    "So the sub-expression `a[1] + a[2]` is computed twice, by two consecutive iterations.\n",
    "What makes CIRE complicated is the generalization to arbitrary expressions, the presence of multiple dimensions, the scheduling strategy due to the trade-off between redundant compute and working set, the co-existance with other optimizations (e.g., blocking, vectorization), and much more. All these aspects won't be treated here. What instead we show below is the effect of CIRE in our running example and the optimization options at user disposal to drive detection and scheduling of the captured redundancies.\n",
    "\n",
    "In our running example, some cross-iteration redundancies are induced by the nested first-order derivatives along `y`. As we see below, these redundancies are captured and assigned to the two-dimensional temporary `r3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define _POSIX_C_SOURCE 200809L\n",
      "#include \"stdlib.h\"\n",
      "#include \"math.h\"\n",
      "#include \"sys/time.h\"\n",
      "#include \"omp.h\"\n",
      "\n",
      "struct dataobj\n",
      "{\n",
      "  void *restrict data;\n",
      "  int * size;\n",
      "  int * npsize;\n",
      "  int * dsize;\n",
      "  int * hsize;\n",
      "  int * hofs;\n",
      "  int * oofs;\n",
      "} ;\n",
      "\n",
      "struct profiler\n",
      "{\n",
      "  double section0;\n",
      "} ;\n",
      "\n",
      "\n",
      "int Kernel(struct dataobj *restrict f_vec, const float h_y, struct dataobj *restrict u_vec, const int y_size, const int z_size, const int time_M, const int time_m, struct profiler * timers, const int x_M, const int x_m, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      "{\n",
      "  float (*restrict f)[f_vec->size[1]][f_vec->size[2]] __attribute__ ((aligned (64))) = (float (*)[f_vec->size[1]][f_vec->size[2]]) f_vec->data;\n",
      "  float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "\n",
      "  float (*r3)[z_size];\n",
      "  posix_memalign((void**)&r3, 64, sizeof(float[y_size + 1][z_size]));\n",
      "\n",
      "  for (int time = time_m, t0 = (time)%(2), t1 = (time + 1)%(2); time <= time_M; time += 1, t0 = (time)%(2), t1 = (time + 1)%(2))\n",
      "  {\n",
      "    struct timeval start_section0, end_section0;\n",
      "    gettimeofday(&start_section0, NULL);\n",
      "    /* Begin section0 */\n",
      "    #pragma omp parallel num_threads(nthreads)\n",
      "    {\n",
      "      #pragma omp for collapse(1) schedule(dynamic,1)\n",
      "      for (int x = x_m; x <= x_M; x += 1)\n",
      "      {\n",
      "        for (int y = y_m - 1; y <= y_M; y += 1)\n",
      "        {\n",
      "          for (int z = z_m; z <= z_M; z += 1)\n",
      "          {\n",
      "            r3[y + 1][z] = -u[t0][x + 2][y + 3][z + 2]/h_y + u[t0][x + 2][y + 4][z + 2]/h_y;\n",
      "          }\n",
      "        }\n",
      "        for (int y = y_m; y <= y_M; y += 1)\n",
      "        {\n",
      "          for (int z = z_m; z <= z_M; z += 1)\n",
      "          {\n",
      "            u[t1][x + 2][y + 2][z + 2] = (-r3[y][z]/h_y + r3[y + 1][z]/h_y)*sin(f[x + 1][y + 1][z + 1]);\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    /* End section0 */\n",
      "    gettimeofday(&end_section0, NULL);\n",
      "    timers->section0 += (double)(end_section0.tv_sec-start_section0.tv_sec)+(double)(end_section0.tv_usec-start_section0.tv_usec)/1000000;\n",
      "  }\n",
      "\n",
      "  free(r3);\n",
      "  return 0;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "op7_omp = Operator(eq, opt=('cire-sops', {'openmp': True}))\n",
    "print(op7_omp)\n",
    "# print(_unidiff_output(str(op7_omp), str(op0_omp)))  # Uncomment to print out the diff only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that since there are no redundancies along `x`, the compiler is sufficiently smart to figure out that `r3` and `u` can safely be computed within the same `x` loop. This is nice -- not only is the reuse distance decreased, but also a grid-sized temporary is avoided.\n",
    "\n",
    "Let's now consider a variant of our running example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define _POSIX_C_SOURCE 200809L\n",
      "#include \"stdlib.h\"\n",
      "#include \"math.h\"\n",
      "#include \"sys/time.h\"\n",
      "#include \"omp.h\"\n",
      "\n",
      "struct dataobj\n",
      "{\n",
      "  void *restrict data;\n",
      "  int * size;\n",
      "  int * npsize;\n",
      "  int * dsize;\n",
      "  int * hsize;\n",
      "  int * hofs;\n",
      "  int * oofs;\n",
      "} ;\n",
      "\n",
      "struct profiler\n",
      "{\n",
      "  double section0;\n",
      "} ;\n",
      "\n",
      "\n",
      "int Kernel(struct dataobj *restrict f_vec, const float h_x, const float h_y, struct dataobj *restrict u_vec, const int x_size, const int y_size, const int z_size, const int time_M, const int time_m, struct profiler * timers, const int x_M, const int x_m, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      "{\n",
      "  float (*restrict f)[f_vec->size[1]][f_vec->size[2]] __attribute__ ((aligned (64))) = (float (*)[f_vec->size[1]][f_vec->size[2]]) f_vec->data;\n",
      "  float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "\n",
      "  float (*r5)[y_size + 1][z_size];\n",
      "  posix_memalign((void**)&r5, 64, sizeof(float[x_size + 1][y_size + 1][z_size]));\n",
      "  float (*r6)[y_size + 1][z_size];\n",
      "  posix_memalign((void**)&r6, 64, sizeof(float[x_size + 1][y_size + 1][z_size]));\n",
      "\n",
      "  for (int time = time_m, t0 = (time)%(2), t1 = (time + 1)%(2); time <= time_M; time += 1, t0 = (time)%(2), t1 = (time + 1)%(2))\n",
      "  {\n",
      "    struct timeval start_section0, end_section0;\n",
      "    gettimeofday(&start_section0, NULL);\n",
      "    /* Begin section0 */\n",
      "    #pragma omp parallel num_threads(nthreads)\n",
      "    {\n",
      "      #pragma omp for collapse(1) schedule(dynamic,1)\n",
      "      for (int x = x_m - 1; x <= x_M; x += 1)\n",
      "      {\n",
      "        for (int y = y_m - 1; y <= y_M; y += 1)\n",
      "        {\n",
      "          for (int z = z_m; z <= z_M; z += 1)\n",
      "          {\n",
      "            r5[x + 1][y + 1][z] = -u[t0][x + 3][y + 2][z + 2]/h_x + u[t0][x + 4][y + 2][z + 2]/h_x;\n",
      "            r6[x + 1][y + 1][z] = -u[t0][x + 2][y + 3][z + 2]/h_y + u[t0][x + 2][y + 4][z + 2]/h_y;\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    #pragma omp parallel num_threads(nthreads)\n",
      "    {\n",
      "      #pragma omp for collapse(1) schedule(dynamic,1)\n",
      "      for (int x = x_m; x <= x_M; x += 1)\n",
      "      {\n",
      "        for (int y = y_m; y <= y_M; y += 1)\n",
      "        {\n",
      "          for (int z = z_m; z <= z_M; z += 1)\n",
      "          {\n",
      "            u[t1][x + 2][y + 2][z + 2] = (-r6[x + 1][y][z]/h_y + r6[x + 1][y + 1][z]/h_y - r5[x][y + 1][z]/h_x + r5[x + 1][y + 1][z]/h_x)*sin(f[x + 1][y + 1][z + 1]);\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    /* End section0 */\n",
      "    gettimeofday(&end_section0, NULL);\n",
      "    timers->section0 += (double)(end_section0.tv_sec-start_section0.tv_sec)+(double)(end_section0.tv_usec-start_section0.tv_usec)/1000000;\n",
      "  }\n",
      "\n",
      "  free(r5);\n",
      "  free(r6);\n",
      "  return 0;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eq = Eq(u.forward, sin(f)*(u.dy.dy + u.dx.dx))\n",
    "op7_b0_omp = Operator(eq, opt=('cire-sops', {'openmp': True}))\n",
    "print(op7_b0_omp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there are now two temporaries, one stemming from `u.dy.dy` and the other from `u.dx.dx`.  A key difference here is that both are grid-sized temporaries. This might seem odd at first -- why should the `u.dy.dy` temporary, that is `r6`, now be a three-dimensional temporary when we know already it could be a two-dimensional temporary? This is merely a compiler heuristic: by adding an extra dimension to `r6`, both temporary can be scheduled within the same loop nest, thus augmenting data reuse and potentially enabling further cross-expression optimizations. We can however tell the compiler not to use this heuristic through the `min-storage` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define _POSIX_C_SOURCE 200809L\n",
      "#include \"stdlib.h\"\n",
      "#include \"math.h\"\n",
      "#include \"sys/time.h\"\n",
      "#include \"xmmintrin.h\"\n",
      "#include \"pmmintrin.h\"\n",
      "#include \"omp.h\"\n",
      "\n",
      "struct dataobj\n",
      "{\n",
      "  void *restrict data;\n",
      "  int * size;\n",
      "  int * npsize;\n",
      "  int * dsize;\n",
      "  int * hsize;\n",
      "  int * hofs;\n",
      "  int * oofs;\n",
      "} ;\n",
      "\n",
      "struct profiler\n",
      "{\n",
      "  double section0;\n",
      "  double section1;\n",
      "} ;\n",
      "\n",
      "void bf0(const float h_y, float *restrict r7_vec, struct dataobj *restrict u_vec, const int t0, const int x0_blk0_size, const int x_M, const int x_m, const int y0_blk0_size, const int y_M, const int y_m, const int y_size, const int z_M, const int z_m, const int z_size, const int nthreads);\n",
      "void bf1(const float h_x, float *restrict r8_vec, struct dataobj *restrict u_vec, const int t0, const int x1_blk0_size, const int x_M, const int x_m, const int x_size, const int y1_blk0_size, const int y_M, const int y_m, const int y_size, const int z_M, const int z_m, const int z_size, const int nthreads);\n",
      "void bf2(const float h_x, const float h_y, float *restrict r1_vec, float *restrict r7_vec, float *restrict r8_vec, struct dataobj *restrict u_vec, const int x_size, const int y_size, const int z_size, const int t1, const int x2_blk0_size, const int x_M, const int x_m, const int y2_blk0_size, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads);\n",
      "\n",
      "int Kernel(struct dataobj *restrict f_vec, const float h_x, const float h_y, struct dataobj *restrict u_vec, const int x_size, const int y_size, const int z_size, const int time_M, const int time_m, struct profiler * timers, const int x0_blk0_size, const int x1_blk0_size, const int x2_blk0_size, const int x_M, const int x_m, const int y0_blk0_size, const int y1_blk0_size, const int y2_blk0_size, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      "{\n",
      "  float (*restrict f)[f_vec->size[1]][f_vec->size[2]] __attribute__ ((aligned (64))) = (float (*)[f_vec->size[1]][f_vec->size[2]]) f_vec->data;\n",
      "\n",
      "  float (*r1)[y_size][z_size];\n",
      "  posix_memalign((void**)&r1, 64, sizeof(float[x_size][y_size][z_size]));\n",
      "  float (*r7)[z_size];\n",
      "  posix_memalign((void**)&r7, 64, sizeof(float[y_size + 1][z_size]));\n",
      "  float (*r8)[y_size][z_size];\n",
      "  posix_memalign((void**)&r8, 64, sizeof(float[x_size + 1][y_size][z_size]));\n",
      "\n",
      "  /* Flush denormal numbers to zero in hardware */\n",
      "  _MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_ON);\n",
      "  _MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);\n",
      "  struct timeval start_section0, end_section0;\n",
      "  gettimeofday(&start_section0, NULL);\n",
      "  /* Begin section0 */\n",
      "  #pragma omp parallel num_threads(nthreads)\n",
      "  {\n",
      "    #pragma omp for collapse(1) schedule(static,1)\n",
      "    for (int x = x_m; x <= x_M; x += 1)\n",
      "    {\n",
      "      for (int y = y_m; y <= y_M; y += 1)\n",
      "      {\n",
      "        #pragma omp simd aligned(f:32)\n",
      "        for (int z = z_m; z <= z_M; z += 1)\n",
      "        {\n",
      "          r1[x][y][z] = sin(f[x + 1][y + 1][z + 1]);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  /* End section0 */\n",
      "  gettimeofday(&end_section0, NULL);\n",
      "  timers->section0 += (double)(end_section0.tv_sec-start_section0.tv_sec)+(double)(end_section0.tv_usec-start_section0.tv_usec)/1000000;\n",
      "  for (int time = time_m, t0 = (time)%(2), t1 = (time + 1)%(2); time <= time_M; time += 1, t0 = (time)%(2), t1 = (time + 1)%(2))\n",
      "  {\n",
      "    struct timeval start_section1, end_section1;\n",
      "    gettimeofday(&start_section1, NULL);\n",
      "    /* Begin section1 */\n",
      "    bf0(h_y,(float *)r7,u_vec,t0,x0_blk0_size,x_M - (x_M - x_m + 1)%(x0_blk0_size),x_m,y0_blk0_size,y_M - (y_M - y_m + 2)%(y0_blk0_size),y_m - 1,y_size,z_M,z_m,z_size,nthreads);\n",
      "    bf0(h_y,(float *)r7,u_vec,t0,x0_blk0_size,x_M - (x_M - x_m + 1)%(x0_blk0_size),x_m,(y_M - y_m + 2)%(y0_blk0_size),y_M,y_M - (y_M - y_m + 2)%(y0_blk0_size) + 1,y_size,z_M,z_m,z_size,nthreads);\n",
      "    bf0(h_y,(float *)r7,u_vec,t0,(x_M - x_m + 1)%(x0_blk0_size),x_M,x_M - (x_M - x_m + 1)%(x0_blk0_size) + 1,y0_blk0_size,y_M - (y_M - y_m + 2)%(y0_blk0_size),y_m - 1,y_size,z_M,z_m,z_size,nthreads);\n",
      "    bf0(h_y,(float *)r7,u_vec,t0,(x_M - x_m + 1)%(x0_blk0_size),x_M,x_M - (x_M - x_m + 1)%(x0_blk0_size) + 1,(y_M - y_m + 2)%(y0_blk0_size),y_M,y_M - (y_M - y_m + 2)%(y0_blk0_size) + 1,y_size,z_M,z_m,z_size,nthreads);\n",
      "    bf1(h_x,(float *)r8,u_vec,t0,x1_blk0_size,x_M - (x_M - x_m + 2)%(x1_blk0_size),x_m - 1,x_size,y1_blk0_size,y_M - (y_M - y_m + 1)%(y1_blk0_size),y_m,y_size,z_M,z_m,z_size,nthreads);\n",
      "    bf1(h_x,(float *)r8,u_vec,t0,x1_blk0_size,x_M - (x_M - x_m + 2)%(x1_blk0_size),x_m - 1,x_size,(y_M - y_m + 1)%(y1_blk0_size),y_M,y_M - (y_M - y_m + 1)%(y1_blk0_size) + 1,y_size,z_M,z_m,z_size,nthreads);\n",
      "    bf1(h_x,(float *)r8,u_vec,t0,(x_M - x_m + 2)%(x1_blk0_size),x_M,x_M - (x_M - x_m + 2)%(x1_blk0_size) + 1,x_size,y1_blk0_size,y_M - (y_M - y_m + 1)%(y1_blk0_size),y_m,y_size,z_M,z_m,z_size,nthreads);\n",
      "    bf1(h_x,(float *)r8,u_vec,t0,(x_M - x_m + 2)%(x1_blk0_size),x_M,x_M - (x_M - x_m + 2)%(x1_blk0_size) + 1,x_size,(y_M - y_m + 1)%(y1_blk0_size),y_M,y_M - (y_M - y_m + 1)%(y1_blk0_size) + 1,y_size,z_M,z_m,z_size,nthreads);\n",
      "    bf2(h_x,h_y,(float *)r1,(float *)r7,(float *)r8,u_vec,x_size,y_size,z_size,t1,x2_blk0_size,x_M - (x_M - x_m + 1)%(x2_blk0_size),x_m,y2_blk0_size,y_M - (y_M - y_m + 1)%(y2_blk0_size),y_m,z_M,z_m,nthreads);\n",
      "    bf2(h_x,h_y,(float *)r1,(float *)r7,(float *)r8,u_vec,x_size,y_size,z_size,t1,x2_blk0_size,x_M - (x_M - x_m + 1)%(x2_blk0_size),x_m,(y_M - y_m + 1)%(y2_blk0_size),y_M,y_M - (y_M - y_m + 1)%(y2_blk0_size) + 1,z_M,z_m,nthreads);\n",
      "    bf2(h_x,h_y,(float *)r1,(float *)r7,(float *)r8,u_vec,x_size,y_size,z_size,t1,(x_M - x_m + 1)%(x2_blk0_size),x_M,x_M - (x_M - x_m + 1)%(x2_blk0_size) + 1,y2_blk0_size,y_M - (y_M - y_m + 1)%(y2_blk0_size),y_m,z_M,z_m,nthreads);\n",
      "    bf2(h_x,h_y,(float *)r1,(float *)r7,(float *)r8,u_vec,x_size,y_size,z_size,t1,(x_M - x_m + 1)%(x2_blk0_size),x_M,x_M - (x_M - x_m + 1)%(x2_blk0_size) + 1,(y_M - y_m + 1)%(y2_blk0_size),y_M,y_M - (y_M - y_m + 1)%(y2_blk0_size) + 1,z_M,z_m,nthreads);\n",
      "    /* End section1 */\n",
      "    gettimeofday(&end_section1, NULL);\n",
      "    timers->section1 += (double)(end_section1.tv_sec-start_section1.tv_sec)+(double)(end_section1.tv_usec-start_section1.tv_usec)/1000000;\n",
      "  }\n",
      "\n",
      "  free(r1);\n",
      "  free(r7);\n",
      "  free(r8);\n",
      "  return 0;\n",
      "}\n",
      "\n",
      "void bf0(const float h_y, float *restrict r7_vec, struct dataobj *restrict u_vec, const int t0, const int x0_blk0_size, const int x_M, const int x_m, const int y0_blk0_size, const int y_M, const int y_m, const int y_size, const int z_M, const int z_m, const int z_size, const int nthreads)\n",
      "{\n",
      "  float (*restrict r7)[z_size] __attribute__ ((aligned (64))) = (float (*)[z_size]) r7_vec;\n",
      "  float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "\n",
      "  if (x0_blk0_size == 0)\n",
      "  {\n",
      "    return;\n",
      "  }\n",
      "  #pragma omp parallel num_threads(nthreads)\n",
      "  {\n",
      "    #pragma omp for collapse(1) schedule(static,1)\n",
      "    for (int x0_blk0 = x_m; x0_blk0 <= x_M; x0_blk0 += x0_blk0_size)\n",
      "    {\n",
      "      for (int y0_blk0 = y_m; y0_blk0 <= y_M; y0_blk0 += y0_blk0_size)\n",
      "      {\n",
      "        for (int x = x0_blk0; x <= x0_blk0 + x0_blk0_size - 1; x += 1)\n",
      "        {\n",
      "          for (int y = y0_blk0; y <= y0_blk0 + y0_blk0_size - 1; y += 1)\n",
      "          {\n",
      "            #pragma omp simd aligned(u:32)\n",
      "            for (int z = z_m; z <= z_M; z += 1)\n",
      "            {\n",
      "              r7[y + 1][z] = (-u[t0][x + 2][y + 3][z + 2] + u[t0][x + 2][y + 4][z + 2])/h_y;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "void bf1(const float h_x, float *restrict r8_vec, struct dataobj *restrict u_vec, const int t0, const int x1_blk0_size, const int x_M, const int x_m, const int x_size, const int y1_blk0_size, const int y_M, const int y_m, const int y_size, const int z_M, const int z_m, const int z_size, const int nthreads)\n",
      "{\n",
      "  float (*restrict r8)[y_size][z_size] __attribute__ ((aligned (64))) = (float (*)[y_size][z_size]) r8_vec;\n",
      "  float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "\n",
      "  if (x1_blk0_size == 0)\n",
      "  {\n",
      "    return;\n",
      "  }\n",
      "  #pragma omp parallel num_threads(nthreads)\n",
      "  {\n",
      "    #pragma omp for collapse(1) schedule(static,1)\n",
      "    for (int x1_blk0 = x_m; x1_blk0 <= x_M; x1_blk0 += x1_blk0_size)\n",
      "    {\n",
      "      for (int y1_blk0 = y_m; y1_blk0 <= y_M; y1_blk0 += y1_blk0_size)\n",
      "      {\n",
      "        for (int x = x1_blk0; x <= x1_blk0 + x1_blk0_size - 1; x += 1)\n",
      "        {\n",
      "          for (int y = y1_blk0; y <= y1_blk0 + y1_blk0_size - 1; y += 1)\n",
      "          {\n",
      "            #pragma omp simd aligned(u:32)\n",
      "            for (int z = z_m; z <= z_M; z += 1)\n",
      "            {\n",
      "              r8[x + 1][y][z] = (-u[t0][x + 3][y + 2][z + 2] + u[t0][x + 4][y + 2][z + 2])/h_x;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "void bf2(const float h_x, const float h_y, float *restrict r1_vec, float *restrict r7_vec, float *restrict r8_vec, struct dataobj *restrict u_vec, const int x_size, const int y_size, const int z_size, const int t1, const int x2_blk0_size, const int x_M, const int x_m, const int y2_blk0_size, const int y_M, const int y_m, const int z_M, const int z_m, const int nthreads)\n",
      "{\n",
      "  float (*restrict r1)[y_size][z_size] __attribute__ ((aligned (64))) = (float (*)[y_size][z_size]) r1_vec;\n",
      "  float (*restrict r7)[z_size] __attribute__ ((aligned (64))) = (float (*)[z_size]) r7_vec;\n",
      "  float (*restrict r8)[y_size][z_size] __attribute__ ((aligned (64))) = (float (*)[y_size][z_size]) r8_vec;\n",
      "  float (*restrict u)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[u_vec->size[1]][u_vec->size[2]][u_vec->size[3]]) u_vec->data;\n",
      "\n",
      "  if (x2_blk0_size == 0)\n",
      "  {\n",
      "    return;\n",
      "  }\n",
      "  #pragma omp parallel num_threads(nthreads)\n",
      "  {\n",
      "    #pragma omp for collapse(1) schedule(static,1)\n",
      "    for (int x2_blk0 = x_m; x2_blk0 <= x_M; x2_blk0 += x2_blk0_size)\n",
      "    {\n",
      "      for (int y2_blk0 = y_m; y2_blk0 <= y_M; y2_blk0 += y2_blk0_size)\n",
      "      {\n",
      "        for (int x = x2_blk0; x <= x2_blk0 + x2_blk0_size - 1; x += 1)\n",
      "        {\n",
      "          for (int y = y2_blk0; y <= y2_blk0 + y2_blk0_size - 1; y += 1)\n",
      "          {\n",
      "            #pragma omp simd aligned(u:32)\n",
      "            for (int z = z_m; z <= z_M; z += 1)\n",
      "            {\n",
      "              u[t1][x + 2][y + 2][z + 2] = ((-r7[y][z] + r7[y + 1][z])/h_y + (-r8[x][y][z] + r8[x + 1][y][z])/h_x)*r1[x][y][z];\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "op7_b1_omp = Operator(eq, opt=('advanced-fsg', {'openmp': True, 'min-storage': True}))\n",
    "print(op7_b1_omp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All optimizations together\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = Operator(eq, openmp=True)  # `openmp=True` shortcut for `opt=('advanced', {'openmp': True})`\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other things that the `advanced` mode does which are not described in this introductory tutorial. Some are visible printing `op` (e.g., the addition of denormal-numbers related macros), others are not (e.g., all of the MPI-related optimizations). This will be covered in another tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Fabio Luporini, Mathias Louboutin, Michael Lange, Navjot Kukreja, Philipp Witte, Jan HÃ¼ckelheim, Charles Yount, Paul H. J. Kelly, Felix J. Herrmann, and Gerard J. Gorman. 2020. Architecture and Performance of Devito, a System for Automated Stencil Computation. ACM Trans. Math. Softw. 46, 1, Article 6 (April 2020), 28 pages. DOI:https://doi.org/10.1145/3374916"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "459.85px",
    "left": "1723.22px",
    "right": "20px",
    "top": "120px",
    "width": "352.767px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
