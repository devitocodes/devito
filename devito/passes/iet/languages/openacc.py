import numpy as np

from devito.arch import AMDGPUX, NVIDIAX
from devito.ir import (Call, DeviceCall, DummyExpr, EntryFunction, List, Block,
                       ParallelTree, Pragma, Return, FindSymbols, make_callable)
from devito.passes import needs_transfer, is_on_device
from devito.passes.iet.definitions import DeviceAwareDataManager
from devito.passes.iet.engine import iet_pass
from devito.passes.iet.orchestration import Orchestrator
from devito.passes.iet.parpragma import (PragmaDeviceAwareTransformer, PragmaLangBB,
                                         PragmaIteration, PragmaTransfer)
from devito.passes.iet.languages.CXX import CXXBB
from devito.passes.iet.languages.openmp import OmpRegion, OmpIteration
from devito.symbolics import FieldFromPointer, Macro, cast_mapper
from devito.tools import filter_ordered, UnboundTuple
from devito.types import Symbol

__all__ = ['DeviceAccizer', 'DeviceAccDataManager', 'AccOrchestrator']


class DeviceAccIteration(PragmaIteration):

    @classmethod
    def _make_construct(cls, **kwargs):
        return 'acc parallel loop'

    @classmethod
    def _make_clauses(cls, ncollapsed=0, reduction=None, tile=None, **kwargs):
        clauses = []

        if tile:
            stile = [str(tile[i]) for i in range(ncollapsed)]
            clauses.append('tile(%s)' % ','.join(stile))
        elif ncollapsed > 1:
            clauses.append('collapse(%d)' % ncollapsed)

        if reduction:
            clauses.append(cls._make_clause_reduction_from_imask(reduction))

        indexeds = FindSymbols('indexeds').visit(kwargs['nodes'])
        deviceptrs = filter_ordered(i.name for i in indexeds if i.function._mem_local)
        presents = filter_ordered(i.name for i in indexeds
                                  if (is_on_device(i, kwargs['gpu_fit']) and
                                      i.name not in deviceptrs))

        # The NVC 20.7 and 20.9 compilers have a bug which triggers data movement for
        # indirectly indexed arrays (e.g., a[b[i]]) unless a present clause is used
        if presents:
            clauses.append("present(%s)" % ",".join(presents))

        if deviceptrs:
            clauses.append("deviceptr(%s)" % ",".join(deviceptrs))

        return clauses


class AccBB(PragmaLangBB):

    BackendCall = DeviceCall

    mapper = {
        # Misc
        'name': 'OpenACC',
        'header': 'openacc.h',
        # Platform mapping
        AMDGPUX: Macro('acc_device_radeon'),
        NVIDIAX: Macro('acc_device_nvidia'),
        # Runtime library
        'init': lambda args:
            Call('acc_init', args),
        'num-devices': lambda args, retobj:
            Call('acc_get_num_devices', args, retobj=retobj),
        'set-device': lambda args:
            Call('acc_set_device_num', args),
        # Pragmas
        'atomic':
            Pragma('acc atomic update'),
        'map-enter-to': lambda f, imask:
            PragmaTransfer('acc enter data copyin(%s%s)', f, imask=imask),
        'map-enter-to-async': lambda f, imask, a:
            PragmaTransfer('acc enter data copyin(%s%s) async(%s)',
                           f, imask=imask, arguments=a),
        'map-enter-alloc': lambda f, imask:
            PragmaTransfer('acc enter data create(%s%s)', f, imask=imask),
        'map-present': lambda f, imask:
            PragmaTransfer('acc data present(%s%s)', f, imask=imask),
        'map-serial-present': lambda i, j:
            Pragma('acc serial present(%s) copyout(%s)', arguments=(i, j)),
        'map-wait': lambda i:
            Pragma('acc wait(%s)', arguments=i),
        'map-update': lambda f, imask:
            PragmaTransfer('acc exit data copyout(%s%s)', f, imask=imask),
        'map-update-host': lambda f, imask:
            PragmaTransfer('acc update self(%s%s)', f, imask=imask),
        'map-update-host-async': lambda f, imask, a:
            PragmaTransfer('acc update self(%s%s) async(%s)',
                           f, imask=imask, arguments=a),
        'map-update-device': lambda f, imask:
            PragmaTransfer('acc update device(%s%s)', f, imask=imask),
        'map-update-device-async': lambda f, imask, a:
            PragmaTransfer('acc update device(%s%s) async(%s)',
                           f, imask=imask, arguments=a),
        'map-release': lambda f, imask:
            PragmaTransfer('acc exit data delete(%s%s)', f, imask=imask),
        'map-release-if': lambda f, imask, a:
            PragmaTransfer('acc exit data delete(%s%s) if(%s)',
                           f, imask=imask, arguments=a),
        'map-exit-delete': lambda f, imask:
            PragmaTransfer('acc exit data delete(%s%s)', f, imask=imask),
        'map-exit-delete-if': lambda f, imask, a:
            PragmaTransfer('acc exit data delete(%s%s) if(%s)',
                           f, imask=imask, arguments=a),
        'memcpy-to-device': lambda i, j, k:
            Call('acc_memcpy_to_device', [i, j, k]),
        'memcpy-to-device-wait': lambda i, j, k, l:
            List(body=[Call('acc_memcpy_to_device_async', [i, j, k, l]),
                       Call('acc_wait', [l])]),
        'device-get':
            Call('acc_get_device_num'),
        'device-alloc': lambda i, *a, retobj=None:
            Call('acc_malloc', (i,), retobj=retobj, cast=True),
        'device-free': lambda i, *a:
            Call('acc_free', (i,))
    }

    mapper.update(CXXBB.mapper)

    Region = OmpRegion
    HostIteration = OmpIteration  # Host parallelism still goes via OpenMP
    DeviceIteration = DeviceAccIteration

    @classmethod
    def _map_to_wait(cls, f, imask=None, qid=None):
        return List(body=[
            cls.mapper['map-enter-to-async'](f, imask, qid),
            cls.mapper['map-wait'](qid)
        ])

    @classmethod
    def _map_present(cls, f, imask=None):
        return cls.mapper['map-present'](f, imask)

    @classmethod
    def _map_wait(cls, qid=None):
        return cls.mapper['map-wait'](qid)

    @classmethod
    def _map_delete(cls, f, imask=None, devicerm=None):
        if devicerm:
            return cls.mapper['map-exit-delete-if'](f, imask, devicerm)
        else:
            return cls.mapper['map-exit-delete'](f, imask)

    @classmethod
    def _map_update_host_async(cls, f, imask=None, qid=None):
        return cls.mapper['map-update-host-async'](f, imask, qid)

    @classmethod
    def _map_update_device_async(cls, f, imask=None, qid=None):
        return cls.mapper['map-update-device-async'](f, imask, qid)


class DeviceAccizer(PragmaDeviceAwareTransformer):

    lang = AccBB

    def _make_partree(self, candidates, nthreads=None):
        assert candidates

        root, collapsable = self._select_candidates(candidates)
        ncollapsable = len(collapsable) + 1

        if self._is_offloadable(root) and \
           all(i.is_Affine for i in [root] + collapsable) and \
           self.par_tile:
            tile = self.par_tile.nextitem()
            assert isinstance(tile, UnboundTuple)

            body = self.DeviceIteration(gpu_fit=self.gpu_fit, tile=tile,
                                        ncollapsed=ncollapsable, **root.args)
            partree = ParallelTree([], body, nthreads=nthreads)

            return root, partree
        else:
            return super()._make_partree(candidates, nthreads)


class DeviceAccDataManager(DeviceAwareDataManager):

    lang = AccBB

    @iet_pass
    def place_devptr(self, iet, **kwargs):
        """
        Transform `iet` such that device pointers are used in DeviceCalls.

        OpenACC provides multiple mechanisms to this purpose, including the
        `acc_deviceptr(f)` routine and the `host_data use_device(f)` pragma.
        However, none of these will work with `nvc` when compiling shared
        libraries (until at least v22.3) due to a known bug -- see this thread
        for more info:

            https://forums.developer.nvidia.com/t/acc-deviceptr-does-not-work-in-\
                openacc-code-dynamically-loaded-from-a-shared-library/211599

        Basically, the issue crops up when OpenACC code is part of a shared library
        that is dlopenâ€™d by an executable that is not linked against the `nvc`'s
        OpenACC runtime library. That's our case, since our executable is Python.

        The following work around does the trick:

          .. code-block:: c

            size_t d_f;
            #pragma acc serial present(f) copyout(d_f)
            {
               d_f = (size_t) f;
            }

        This method creates an IET along the lines of the code snippet above.
        """
        if not isinstance(iet, EntryFunction):
            return iet, {}

        symbols = FindSymbols('basics').visit(iet)
        functions = [f for f in symbols if needs_transfer(f, self.gpu_fit)]

        efuncs = []
        calls = []
        for f in functions:
            dmap = f.dmap
            hp = f.indexed

            tdp = Symbol(name="dptr", dtype=np.uint64)
            init = DummyExpr(tdp, 0, init=True)

            dpf = List(body=[
                self.lang.mapper['map-serial-present'](hp, tdp),
                Block(body=DummyExpr(tdp, cast_mapper[tdp.dtype](hp)))
            ])

            ffp = FieldFromPointer(f._C_field_dmap, f._C_symbol)
            ctdp = cast_mapper[(hp.dtype, '*')](tdp)
            cast = DummyExpr(ffp, ctdp)

            ret = Return(ctdp)

            body = List(body=[init, dpf, cast, ret])

            name = self.sregistry.make_name(prefix='map_device_ptr')
            efuncs.append(make_callable(name, body, retval=hp))

            if dmap in symbols:
                calls.append(Call(name, f, retobj=dmap))
            else:
                calls.append(Call(name, f))

        body = iet.body._rebuild(maps=iet.body.maps + tuple(calls))
        iet = iet._rebuild(body=body)

        return iet, {'efuncs': efuncs}


class AccOrchestrator(Orchestrator):
    lang = AccBB
